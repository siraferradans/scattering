{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.cross_validation import cross_val_score, KFold, ShuffleSplit,cross_val_predict\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: Quadro K5000 (CNMeM is disabled, cuDNN 4007)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images (in BW!!):\n",
      "X_train shape:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/users/data/ferradan/ScatteringPython/scattering/scattering/scattering.py:142: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  S = np.ndarray((num_signals,num_coefs,spatial_coefs,spatial_coefs))\n",
      "/users/data/ferradan/ScatteringPython/scattering/scattering/scattering.py:119: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  return 2 ** (J - 1) *Img_filtered[...,::ds,::ds].copy()\n",
      "/users/data/ferradan/ScatteringPython/scattering/scattering/scattering.py:149: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  Sview.shape=(num_signals,J,L,spatial_coefs,spatial_coefs)\n",
      "/users/data/ferradan/ScatteringPython/scattering/scattering/scattering.py:173: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  S2norder = S[:,J*L+1:num_coefs,:,:] # view of the data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (60000, 32, 32)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "60000  images loaded in  1.6775035858154297  secs\n",
      "shape data: (60000, 32, 32)\n",
      "Create filters:\n",
      "Compute  60000  scatterings:\n",
      "0 / 60000\n",
      "500 / 60000\n",
      "1000 / 60000\n",
      "1500 / 60000\n",
      "2000 / 60000\n",
      "2500 / 60000\n",
      "3000 / 60000\n",
      "3500 / 60000\n",
      "4000 / 60000\n",
      "4500 / 60000\n",
      "5000 / 60000\n",
      "5500 / 60000\n",
      "6000 / 60000\n",
      "6500 / 60000\n",
      "7000 / 60000\n",
      "7500 / 60000\n",
      "8000 / 60000\n",
      "8500 / 60000\n",
      "9000 / 60000\n",
      "9500 / 60000\n",
      "10000 / 60000\n",
      "10500 / 60000\n",
      "11000 / 60000\n",
      "11500 / 60000\n",
      "12000 / 60000\n",
      "12500 / 60000\n",
      "13000 / 60000\n",
      "13500 / 60000\n",
      "14000 / 60000\n",
      "14500 / 60000\n",
      "15000 / 60000\n",
      "15500 / 60000\n",
      "16000 / 60000\n",
      "16500 / 60000\n",
      "17000 / 60000\n",
      "17500 / 60000\n",
      "18000 / 60000\n",
      "18500 / 60000\n",
      "19000 / 60000\n",
      "19500 / 60000\n",
      "20000 / 60000\n",
      "20500 / 60000\n",
      "21000 / 60000\n",
      "21500 / 60000\n",
      "22000 / 60000\n",
      "22500 / 60000\n",
      "23000 / 60000\n",
      "23500 / 60000\n",
      "24000 / 60000\n",
      "24500 / 60000\n",
      "25000 / 60000\n",
      "25500 / 60000\n",
      "26000 / 60000\n",
      "26500 / 60000\n",
      "27000 / 60000\n",
      "27500 / 60000\n",
      "28000 / 60000\n",
      "28500 / 60000\n",
      "29000 / 60000\n",
      "29500 / 60000\n",
      "30000 / 60000\n",
      "30500 / 60000\n",
      "31000 / 60000\n",
      "31500 / 60000\n",
      "32000 / 60000\n",
      "32500 / 60000\n",
      "33000 / 60000\n",
      "33500 / 60000\n",
      "34000 / 60000\n",
      "34500 / 60000\n",
      "35000 / 60000\n",
      "35500 / 60000\n",
      "36000 / 60000\n",
      "36500 / 60000\n",
      "37000 / 60000\n",
      "37500 / 60000\n",
      "38000 / 60000\n",
      "38500 / 60000\n",
      "39000 / 60000\n",
      "39500 / 60000\n",
      "40000 / 60000\n",
      "40500 / 60000\n",
      "41000 / 60000\n",
      "41500 / 60000\n",
      "42000 / 60000\n",
      "42500 / 60000\n",
      "43000 / 60000\n",
      "43500 / 60000\n",
      "44000 / 60000\n",
      "44500 / 60000\n",
      "45000 / 60000\n",
      "45500 / 60000\n",
      "46000 / 60000\n",
      "46500 / 60000\n",
      "47000 / 60000\n",
      "47500 / 60000\n",
      "48000 / 60000\n",
      "48500 / 60000\n",
      "49000 / 60000\n",
      "49500 / 60000\n",
      "50000 / 60000\n",
      "50500 / 60000\n",
      "51000 / 60000\n",
      "51500 / 60000\n",
      "52000 / 60000\n",
      "52500 / 60000\n",
      "53000 / 60000\n",
      "53500 / 60000\n",
      "54000 / 60000\n",
      "54500 / 60000\n",
      "55000 / 60000\n",
      "55500 / 60000\n",
      "56000 / 60000\n",
      "56500 / 60000\n",
      "57000 / 60000\n",
      "57500 / 60000\n",
      "58000 / 60000\n",
      "58500 / 60000\n",
      "59000 / 60000\n",
      "59500 / 60000\n",
      "60000  scat. features computed in  1331.6229133605957  secs.\n",
      "Now testing set:\n",
      "0 / 10000\n",
      "500 / 10000\n",
      "1000 / 10000\n",
      "1500 / 10000\n",
      "2000 / 10000\n",
      "2500 / 10000\n",
      "3000 / 10000\n",
      "3500 / 10000\n",
      "4000 / 10000\n",
      "4500 / 10000\n",
      "5000 / 10000\n",
      "5500 / 10000\n",
      "6000 / 10000\n",
      "6500 / 10000\n",
      "7000 / 10000\n",
      "7500 / 10000\n",
      "8000 / 10000\n",
      "8500 / 10000\n",
      "9000 / 10000\n",
      "9500 / 10000\n",
      "10000  scat. features computed in  212.78962755203247  secs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/data/ferradan/ScatteringPython/scattering/scattering/scattering.py:174: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  S2norder.shape = (num_signals, sec_order_coefs/L, L, spatial_coefs, spatial_coefs)\n"
     ]
    }
   ],
   "source": [
    "n = 60000\n",
    "from load_mnist_db import load_scattering_mnist\n",
    "\n",
    "import time as time\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "num_images = n\n",
    "px=32\n",
    "\n",
    "Xtrain,ytrain,Xtest,ytest = load_scattering_mnist(num_images = num_images, px=px,J=3,L=6,m=2)\n",
    "Xtrain_1d = Xtrain.reshape((len(Xtrain),-1))\n",
    "num_samples,num_features = Xtrain_1d.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 8128)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_1d = Xtrain.reshape((len(Xtrain),-1))\n",
    "Xtest_1d = Xtest.reshape((len(Xtest),-1))\n",
    "Xtest_1d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gethomogeneus_datast(X,y,d,n):\n",
    "    num_per_class = np.int(n/d)\n",
    "    ytrain=np.reshape(y,(y.shape[0],))\n",
    "\n",
    "    X_out = []#np.zeros(n,X.shape[1],X.shape[2],X.shape[3])\n",
    "    y_out = []\n",
    "    for i_d in np.arange(d):\n",
    "        indx = np.where(ytrain.ravel()==i_d)\n",
    "\n",
    "        X_out.append(X[indx[0][0:num_per_class],:])\n",
    "        y_out.append(ytrain[indx[0][0:num_per_class],])\n",
    "\n",
    "    \n",
    "    X_out = np.concatenate(X_out,axis=0)\n",
    "    y_out = np.concatenate(y_out,axis=0)\n",
    "    #print(X_out.shape)\n",
    "    #print(y_out)\n",
    "    return X_out,y_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### Gaussian kernel grid search\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
    "\n",
    "\n",
    "#gammavec = 10**np.arange(-2.25,-2.15,0.01)# got 0.00616595 #np.array(10**np.arange(-3,-0.5,0.1)) got 0.0063095734448\n",
    "gammavec = 10**np.arange(0.,0.15,0.05) #0.3-1.5(0.25) got 1.995 #(-1,0.5,0.1) got 0.5\n",
    "gammavec.shape = (gammavec.shape[0])\n",
    "#Cvec = np.arange(3.15,3.55,0.10) #got 3.25 #np.arange(0.5,4,0.25) got 3.25\n",
    "Cvec = np.arange(4.1,4.4,0.1) #3-5(0.25))got 4.25  #4-5, 4.0 (0.5)\n",
    "Cvec.shape=(Cvec.shape[0])\n",
    "parameters = {\"C\":Cvec,\n",
    "              \"gamma\":gammavec}\n",
    "\n",
    "gs_gaussian = GridSearchCV(SVC(kernel='rbf'),parameters)\n",
    "pip_gaussian = make_pipeline(MinMaxScaler((-1,1)),Normalizer(),gs_gaussian)\n",
    "n = 10000\n",
    "Xa,ya=gethomogeneus_datast(Xtrain_1d,ytrain,10,n)\n",
    "\n",
    "np.histogram(ya)\n",
    "\n",
    "pip_gaussian.fit(Xa,ya.ravel())\n",
    "\n",
    "bestC = gs_gaussian.best_params_['C']\n",
    "bestgamma = gs_gaussian.best_params_['gamma']\n",
    "print(bestgamma)\n",
    "print(bestC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.log10(1.1220184543)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bestC = 4.1\n",
    "bestgamma =10**0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'gammavec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-e5c3041e8728>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog10\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbestgamma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgammavec\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2.25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2.15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#print(gammavec)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbestgamma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gammavec' is not defined"
     ]
    }
   ],
   "source": [
    "print(np.log10(bestgamma))\n",
    "gammavec\n",
    "print(10**np.arange(-2.25,-2.15,0.01))\n",
    "#print(gammavec)\n",
    "print(bestgamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(bestC)\n",
    "Cvec\n",
    "np.arange(3.15,3.55,0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.0592]\n",
      "[ 0.027]"
     ]
    }
   ],
   "source": [
    "########### Gaussian kernel methods\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler, Normalizer\n",
    "\n",
    "num_items,num_features = Xtrain_1d.shape\n",
    "\n",
    "ns = [300, 1000, 2000, 5000, 10000,20000, 40000, 60000]\n",
    "score_gaussian = np.zeros((len(ns),1))\n",
    "for i,n in enumerate(ns):\n",
    "    #  gs_gaussian = GridSearchCV(SVC(kernel='rbf'),param_grid=parameters)\n",
    "    gs_gaussian = SVC(kernel='rbf',C=bestC,gamma=bestgamma)\n",
    "    pip_gaussian = make_pipeline(MinMaxScaler((-1,1)),Normalizer(),gs_gaussian)\n",
    "\n",
    "#    gs_gaussian = SVC(kernel='rbf',gamma=0.0018)\n",
    "#    pip_gaussian = make_pipeline(StandardScaler(),Normalizer(),gs_gaussian)\n",
    "\n",
    "    Xa,ya=gethomogeneus_datast(Xtrain_1d,ytrain,10,n) \n",
    "    pip_gaussian.fit(Xa,ya)\n",
    "    out=pip_gaussian.predict(Xtest_1d)\n",
    "    score_gaussian[i] = 1.0-accuracy_score(ytest, out)\n",
    "    print(score_gaussian[i])\n",
    "    \n",
    "score_gaussian\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(bestC)\n",
    "print(bestgamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.arange(-3,-0.5,0.1).shape\n",
    "n = 10000\n",
    "Xa,ya=gethomogeneus_datast(Xtrain_1d,ytrain,10,n) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler, Normalizer\n",
    "\n",
    "gammavec = np.array(10**np.arange(0.46,0.52,0.01)) #np.array(10**np.arange(-0.1,1,0.3))  best 0.5 #np.array(10**np.arange(-3,-0.5,0.1)) got 0.0063095734448\n",
    "gammavec.shape = (6)\n",
    "Cvec = np.arange(3.8,3.95,0.05)\n",
    "#Cvec.append(1) #np.arange(3.15,3.55,0.10) #np.arange(0.5,4,0.25) got 3.25\n",
    "Cvec.shape=(4)\n",
    "parameters = {\"C\":Cvec,\n",
    "              \"gamma\":gammavec}\n",
    "\n",
    "gs_gaussian = GridSearchCV(SVC(kernel='rbf'),parameters)\n",
    "pip_gaussian = make_pipeline(MinMaxScaler((-1,1)),Normalizer(),gs_gaussian)\n",
    "pip_gaussian.fit(Xa,ya)\n",
    "\n",
    "bestC = gs_gaussian.best_params_['C']\n",
    "bestgamma = gs_gaussian.best_params_['gamma']\n",
    "print(bestC)\n",
    "print(bestgamma)\n",
    "gs_gaussian = SVC(kernel='rbf',C=bestC,gamma=bestgamma)\n",
    "pip_gaussian = make_pipeline(MinMaxScaler((-1,1)),Normalizer(),gs_gaussian)\n",
    "\n",
    "pip_gaussian.fit(Xa,ya)\n",
    "out=pip_gaussian.predict(Xtest_1d)\n",
    "score = 1.0-accuracy_score(ytest, out)\n",
    "print(score) # C=3, gamma = 3.16227766, score=0.0139\n",
    "#C=3.9, gamma = 2.88403150313 score=0.0137"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler,Normalizer\n",
    "\n",
    "n = 10000\n",
    "Xa,ya=gethomogeneus_datast(Xtrain_1d,ytrain,10,n)    \n",
    "\n",
    "parameters = {'C':np.arange(0.75,5,0.25)}\n",
    "gs_gaussian = GridSearchCV(SVC(kernel='linear'),param_grid=parameters)\n",
    "\n",
    "pip_gaussian = make_pipeline(MinMaxScaler((-1,1)),Normalizer(),gs_gaussian)\n",
    "pip_gaussian.fit(Xa,ya)\n",
    "\n",
    "C_best = gs_gaussian.best_params_['C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "C_best = gs_gaussian.best_params_['C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### linear\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler,Normalizer\n",
    "\n",
    "num_items,num_features = Xtrain_1d.shape\n",
    "\n",
    "ns = [300, 1000, 2000, 5000, 10000]\n",
    "score_gaussian = np.zeros((5,1))\n",
    "for i,n in enumerate(ns):\n",
    "    #  gs_gaussian = GridSearchCV(SVC(kernel='rbf'),param_grid=parameters)\n",
    "    gs_gaussian = SVC(kernel='linear',C=C_best)\n",
    "    pip_gaussian = make_pipeline(MinMaxScaler((-1,1)),Normalizer(),gs_gaussian)\n",
    "\n",
    "#    gs_gaussian = SVC(kernel='rbf',gamma=0.0018)\n",
    "#    pip_gaussian = make_pipeline(StandardScaler(),Normalizer(),gs_gaussian)\n",
    "\n",
    "    Xa,ya=gethomogeneus_datast(Xtrain_1d,ytrain,10,n)    \n",
    "    pip_gaussian.fit(Xa,ya)\n",
    "    out=pip_gaussian.predict(Xtest_1d)\n",
    "    score_gaussian[i] = 1.0-accuracy_score(ytest, out)\n",
    "    print(score_gaussian[i])\n",
    "    \n",
    "score_gaussian\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtest_1d = Xtest.reshape((len(Xtest),-1))\n",
    "Xe = normalize(Xtest_1d)\n",
    "Xe = scale(Xe)\n",
    "\n",
    "predictedY = gs_linear.predict(Xe)\n",
    "score = accuracy_score(ytest, predictedY)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "parameters = {\"C\":[1,1.1,1.11,1.05] ,\n",
    "              \"gamma\":[0.1/num_features,1/num_features,10./num_features]}\n",
    "gs_gaussian = GridSearchCV(SVC(kernel='rbf'),param_grid=parameters)\n",
    "\n",
    "X = normalize(Xtrain_1d[0:n,:])\n",
    "X = scale(X)\n",
    "\n",
    "gs_gaussian.fit(X,ytrain[0:n])\n",
    "gs_gaussian.best_params_\n",
    "\n",
    "Xtest_1d = Xtest.reshape((len(Xtest),-1))\n",
    "Xe = normalize(Xtest_1d)\n",
    "Xe = scale(Xe)\n",
    "\n",
    "predictedY = gs_gaussian.predict(Xe)\n",
    "score = accuracy_score(ytest, predictedY)\n",
    "score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('mine:',np.sum(ytest==predictedY)/len(Xtest))\n",
    "print('two:',accuracy_score(ytest, predictedY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#sampling the whole dataset \n",
    "n = 300\n",
    "train_size=n/60000\n",
    "test_size=0.5*n/60000\n",
    "\n",
    "pipeline = make_pipeline(Normalizer(),StandardScaler(),gs)\n",
    "\n",
    "# pipeline = make_pipeline(Normalizer(),StandardScaler(),SVC(C=1.0, kernel='rbf', verbose=False))\n",
    "cv = ShuffleSplit(n,n_iter=3,test_size=test_size, train_size=train_size)\n",
    "\n",
    "scores = cross_val_score(pipeline,Xtrain_1d[0:n,:],ytrain[0:n],cv=10)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % ((1.0-scores.mean())*100, scores.std() * 2*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gs.best_params_\n",
    "pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.cross_validation import cross_val_score, KFold, ShuffleSplit,cross_val_predict\n",
    "from sklearn import metrics\n",
    "\n",
    "def from_features_to_classif_scores(features,labels,ftest,ltest):\n",
    "    #stack them for learning\n",
    "    features = features.reshape((len(features),-1))\n",
    "    ftest = ftest.reshape((len(ftest),-1))\n",
    "    # apply pipeline\n",
    "    n = len(features)\n",
    "    \n",
    "    pipeline = make_pipeline(Normalizer(),StandardScaler(),SVC(C=1.0, kernel='rbf', verbose=False))\n",
    "    cv = ShuffleSplit(n,n_iter=3,test_size=0.1, train_size=0.9)\n",
    "    \n",
    "    scores = cross_val_score(pipeline,features,labels,cv=10)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % ((1.0-scores.mean())*100, scores.std() * 2*100))\n",
    "    print('min score:',(1.0-scores.max())*100)\n",
    "    return pipeline,scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from load_mnist_db import load_scattering_mnist\n",
    "import time as time\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "\n",
    "num_images = 60000\n",
    "px=32\n",
    "\n",
    "Xtrain,ytrain,Xtest,ytest = load_scattering_mnist(num_images = num_images, px=px,J=3,L=8)\n",
    "\n",
    "num_points = [330, 1100, 2200, 5500, 11000, 22000, 60000]\n",
    "for n in num_points:\n",
    "    print('n=',n)\n",
    "    pipeline, test_err = from_features_to_classif_scores(Xtrain[0:n,:,:,:],ytrain[0:n],Xtest[0:n,:,:,:],ytest[0:n])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X_train = Xtrain\n",
    "y_train = ytrain\n",
    "X_train = features.reshape((len(X_train),-1))\n",
    "X_test = Xtest.reshape((len(Xtest),-1))\n",
    "\n",
    "# apply pipeline\n",
    "n = len(X_train)\n",
    "\n",
    "pipeline = make_pipeline(Normalizer(),StandardScaler(),SVC(C=1.0, kernel='rbf', verbose=True))\n",
    "#cv = ShuffleSplit(n,n_iter=3,test_size=1, train_size=1)\n",
    "\n",
    "normalizer = Normalizer()\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_normalized = normalizer.transform(X_train)\n",
    "X_train_transformed = scaler.transform(X_train_normalized)\n",
    "\n",
    "clf = SVC(kernel='rbf', C=1, verbose=True).fit(X_train_transformed, y_train)\n",
    "\n",
    "X_test_normalized = normalizer.transform(X_test)\n",
    "X_test_transformed = scaler.transform(X_test_normalized)\n",
    "\n",
    "clf.score(Xtest, ytest)   \n",
    "\n",
    "\n",
    "print('score:',scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

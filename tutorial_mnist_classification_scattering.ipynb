{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# MNIST classification tutorial\n",
    "\n",
    "This tutorial wants to show how the scattering transform can be successfully used in classification for the MNIST data base. The results and parameters were set following the table 4 of the paper :\n",
    "\n",
    "   - Bruna, J., Mallat, S. 'Invariant Scattering Convolutional Networks'. IEEE Transactions on PAMI, 2012.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images (in BW!!):\n",
      "X_train shape: (60000, 32, 32)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "60000  images loaded in  2.8638360500335693  secs\n",
      "shape data: (60000, 32, 32)\n",
      "Create filters:\n",
      "Compute  60000  scatterings:\n",
      "0 / 60000\n",
      "500 / 60000\n",
      "1000 / 60000\n",
      "1500 / 60000\n",
      "2000 / 60000\n",
      "2500 / 60000\n",
      "3000 / 60000\n",
      "3500 / 60000\n",
      "4000 / 60000\n",
      "4500 / 60000\n",
      "5000 / 60000\n",
      "5500 / 60000\n",
      "6000 / 60000\n",
      "6500 / 60000\n",
      "7000 / 60000\n",
      "7500 / 60000\n",
      "8000 / 60000\n",
      "8500 / 60000\n",
      "9000 / 60000\n",
      "9500 / 60000\n",
      "10000 / 60000\n",
      "10500 / 60000\n",
      "11000 / 60000\n",
      "11500 / 60000\n",
      "12000 / 60000\n",
      "12500 / 60000\n",
      "13000 / 60000\n",
      "13500 / 60000\n",
      "14000 / 60000\n",
      "14500 / 60000\n",
      "15000 / 60000\n",
      "15500 / 60000\n",
      "16000 / 60000\n",
      "16500 / 60000\n",
      "17000 / 60000\n",
      "17500 / 60000\n",
      "18000 / 60000\n",
      "18500 / 60000\n",
      "19000 / 60000\n",
      "19500 / 60000\n",
      "20000 / 60000\n",
      "20500 / 60000\n",
      "21000 / 60000\n",
      "21500 / 60000\n",
      "22000 / 60000\n",
      "22500 / 60000\n",
      "23000 / 60000\n",
      "23500 / 60000\n",
      "24000 / 60000\n",
      "24500 / 60000\n",
      "25000 / 60000\n",
      "25500 / 60000\n",
      "26000 / 60000\n",
      "26500 / 60000\n",
      "27000 / 60000\n",
      "27500 / 60000\n",
      "28000 / 60000\n",
      "28500 / 60000\n",
      "29000 / 60000\n",
      "29500 / 60000\n",
      "30000 / 60000\n",
      "30500 / 60000\n",
      "31000 / 60000\n",
      "31500 / 60000\n",
      "32000 / 60000\n",
      "32500 / 60000\n",
      "33000 / 60000\n",
      "33500 / 60000\n",
      "34000 / 60000\n",
      "34500 / 60000\n",
      "35000 / 60000\n",
      "35500 / 60000\n",
      "36000 / 60000\n",
      "36500 / 60000\n",
      "37000 / 60000\n",
      "37500 / 60000\n",
      "38000 / 60000\n",
      "38500 / 60000\n",
      "39000 / 60000\n",
      "39500 / 60000\n",
      "40000 / 60000\n",
      "40500 / 60000\n",
      "41000 / 60000\n",
      "41500 / 60000\n",
      "42000 / 60000\n",
      "42500 / 60000\n",
      "43000 / 60000\n",
      "43500 / 60000\n",
      "44000 / 60000\n",
      "44500 / 60000\n",
      "45000 / 60000\n",
      "45500 / 60000\n",
      "46000 / 60000\n",
      "46500 / 60000\n",
      "47000 / 60000\n",
      "47500 / 60000\n",
      "48000 / 60000\n",
      "48500 / 60000\n",
      "49000 / 60000\n",
      "49500 / 60000\n",
      "50000 / 60000\n",
      "50500 / 60000\n",
      "51000 / 60000\n",
      "51500 / 60000\n",
      "52000 / 60000\n",
      "52500 / 60000\n",
      "53000 / 60000\n",
      "53500 / 60000\n",
      "54000 / 60000\n",
      "54500 / 60000\n",
      "55000 / 60000\n",
      "55500 / 60000\n",
      "56000 / 60000\n",
      "56500 / 60000\n",
      "57000 / 60000\n",
      "57500 / 60000\n",
      "58000 / 60000\n",
      "58500 / 60000\n",
      "59000 / 60000\n",
      "59500 / 60000\n",
      "60000  scat. features computed in  1604.591773033142  secs.\n",
      "Now testing set:\n",
      "0 / 10000\n",
      "500 / 10000\n",
      "1000 / 10000\n",
      "1500 / 10000\n",
      "2000 / 10000\n",
      "2500 / 10000\n",
      "3000 / 10000\n",
      "3500 / 10000\n",
      "4000 / 10000\n",
      "4500 / 10000\n",
      "5000 / 10000\n",
      "5500 / 10000\n",
      "6000 / 10000\n",
      "6500 / 10000\n",
      "7000 / 10000\n",
      "7500 / 10000\n",
      "8000 / 10000\n",
      "8500 / 10000\n",
      "9000 / 10000\n",
      "9500 / 10000\n",
      "10000  scat. features computed in  222.5818989276886  secs.\n"
     ]
    }
   ],
   "source": [
    "#Load data and compute the scattering transform of each image\n",
    "from load_mnist_db import load_scattering_multiresolution_mnist\n",
    "from keras.datasets import mnist\n",
    "num_images = 60000\n",
    "px=32\n",
    "\n",
    "Xtrain,ytrain,Xtest,ytest = load_scattering_multiresolution_mnist(num_images = num_images, px=px,J=3,L=6,m=2)\n",
    "Xtrain_1d = Xtrain.reshape((len(Xtrain),-1))\n",
    "num_samples,num_features = Xtrain_1d.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 8128)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_1d = Xtrain.reshape((len(Xtrain),-1))\n",
    "Xtest_1d = Xtest.reshape((len(Xtest),-1))\n",
    "print('Feature vector:')\n",
    "Xtrain_1d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gethomogeneus_datast(X,y,d,n):\n",
    "    num_per_class = np.int(n/d)\n",
    "    ytrain=np.reshape(y,(y.shape[0],))\n",
    "\n",
    "    X_out = []#np.zeros(n,X.shape[1],X.shape[2],X.shape[3])\n",
    "    y_out = []\n",
    "    for i_d in np.arange(d):\n",
    "        indx = np.where(ytrain.ravel()==i_d)\n",
    "\n",
    "        X_out.append(X[indx[0][0:num_per_class],:])\n",
    "        y_out.append(ytrain[indx[0][0:num_per_class],])\n",
    "\n",
    "    \n",
    "    X_out = np.concatenate(X_out,axis=0)\n",
    "    y_out = np.concatenate(y_out,axis=0)\n",
    "    #print(X_out.shape)\n",
    "    #print(y_out)\n",
    "    return X_out,y_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gammavec = 10**np.arange(-3,-1,0.1)\n",
    "gammavec.shape = (gammavec.shape[0])\n",
    "gammavec.shape\n",
    "Cvec = np.arange(1,3.5,0.5)\n",
    "Cvec.shape=(Cvec.shape[0])\n",
    "Cvec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1220184543\n",
      "4.1\n"
     ]
    }
   ],
   "source": [
    "##### Gaussian kernel Grid Search\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
    "\n",
    "# - define range of parameters to check in the crossvalidation\n",
    "gammavec = 10**np.arange(0.,0.15,0.05) #0.3-1.5(0.25) got 1.995 #(-1,0.5,0.1) got 0.5\n",
    "gammavec.shape = (gammavec.shape[0])\n",
    "Cvec = np.arange(4.1,4.4,0.1) #3-5(0.25))got 4.25  #4-5, 4.0 (0.5)\n",
    "Cvec.shape=(Cvec.shape[0])\n",
    "parameters = {\"C\":Cvec,\n",
    "              \"gamma\":gammavec}\n",
    "\n",
    "gs_gaussian = GridSearchCV(SVC(kernel='rbf'),parameters)\n",
    "pip_gaussian = make_pipeline(MinMaxScaler((-1,1)),Normalizer(),gs_gaussian)\n",
    "\n",
    "# - find the best parameters with a subset of the training set (otherwise too long to compute)\n",
    "n = 10000\n",
    "Xa,ya=gethomogeneus_datast(Xtrain_1d,ytrain,10,n)\n",
    "pip_gaussian.fit(Xa,ya.ravel())\n",
    "\n",
    "bestC = gs_gaussian.best_params_['C']\n",
    "bestgamma = gs_gaussian.best_params_['gamma']\n",
    "print('Best gamma found:',bestgamma)\n",
    "print('Best C found:',bestC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Xtrain_1d' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1da27641f217>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m########### Evaluate for different number of instances in the traning data (following Table 4 of paper)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnum_items\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXtrain_1d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m60000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mscore_gaussian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Xtrain_1d' is not defined"
     ]
    }
   ],
   "source": [
    "########### Evaluate for different number of instances in the traning data (following Table 4 of paper)\n",
    "\n",
    "num_items,num_features = Xtrain_1d.shape\n",
    "ns = [300, 1000, 2000, 5000, 10000,20000, 40000, 60000]\n",
    "score_gaussian = np.zeros((len(ns),1))\n",
    "print('Evaluate score for different number of training samples: ')\n",
    "\n",
    "for i,n in enumerate(ns):\n",
    "    gs_gaussian = SVC(kernel='rbf',C=bestC,gamma=bestgamma)\n",
    "    pip_gaussian = make_pipeline(MinMaxScaler((-1,1)),Normalizer(),gs_gaussian)\n",
    "\n",
    "    Xa,ya=gethomogeneus_datast(Xtrain_1d,ytrain,10,n) \n",
    "    pip_gaussian.fit(Xa,ya)\n",
    "    out=pip_gaussian.predict(Xtest_1d)\n",
    "    score_gaussian[i] = 1.0-accuracy_score(ytest, out)\n",
    "    print(n,' samples   socer:', score_gaussian[i])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

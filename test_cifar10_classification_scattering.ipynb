{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "n = 60000\n",
    "#from load_cifar10_db import load_images_cifar,load_scattering_cifar\n",
    "#X_train, y_train, X_test, y_test = load_scattering_cifar(num_images = 150000, J=3,L=8,m=1, sigma_phi=0.8, sigma_xi=0.8)\n",
    "#\n",
    "\n",
    "#Load the saved data    \n",
    "f = h5py.File('./cifar10_scatteringdata.mat')\n",
    "X_train = np.array(f['X_train']).astype('single')\n",
    "y_train = np.array(f['y_train']).astype('single')\n",
    "X_test = np.array(f['X_test']).astype('single')\n",
    "y_test = np.array(f['y_test']).astype('single')\n",
    "m = np.array(f['m'])\n",
    "J = np.array(f['J'])\n",
    "L = np.array(f['L'])\n",
    "\n",
    "num_samples = X_train.shape[0]\n",
    "\n",
    "\n",
    "X_train.shape\n",
    "Xtrain_1d = X_train.reshape((50000,75*8*8))\n",
    "Xtest_1d = X_test.reshape((10000,75*8*8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e862698b3e60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./cifar10_scatteringdata_sigma08.mat'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mhf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'X_train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mhf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y_train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mhf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'X_test'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Save data in a .mat file\n",
    "import h5py\n",
    "m=1\n",
    "J=3\n",
    "L=8\n",
    "with h5py.File('./cifar10_scatteringdata_sigma08.mat','w') as hf:\n",
    "    hf.create_dataset('X_train', data=X_train)\n",
    "    hf.create_dataset('y_train', data=y_train)\n",
    "    hf.create_dataset('X_test' , data = X_test)\n",
    "    hf.create_dataset('y_test' , data = y_test)\n",
    "    hf.create_dataset('m' , data = m)\n",
    "    hf.create_dataset('J' , data = J)\n",
    "    hf.create_dataset('L' , data = L)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def gethomogeneus_datast(X,y,d,n):\n",
    "    num_per_class = np.int(n/d)\n",
    "    ytrain=np.reshape(y,(y.shape[0],))\n",
    "\n",
    "    X_out = []#np.zeros(n,X.shape[1],X.shape[2],X.shape[3])\n",
    "    y_out = []\n",
    "    for i_d in np.arange(d):\n",
    "        indx = np.where(ytrain.ravel()==i_d)\n",
    "\n",
    "        X_out.append(X[indx[0][0:num_per_class],:])\n",
    "        y_out.append(ytrain[indx[0][0:num_per_class],])\n",
    "\n",
    "    \n",
    "    X_out = np.concatenate(X_out,axis=0)\n",
    "    y_out = np.concatenate(y_out,axis=0)\n",
    "    #print(X_out.shape)\n",
    "    #print(y_out)\n",
    "    return X_out,y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Testing specific values\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "n = 300\n",
    "Xa,ya=gethomogeneus_datast(Xtrain_1d,y_train,10,n)    \n",
    "\n",
    "bestC = 4.4\n",
    "bestgamma = 10**-3.5 \n",
    "print('C=',bestC)\n",
    "print('gamma=',bestgamma)\n",
    "gs_gaussian = SVC(kernel='rbf',C=bestC,gamma=bestgamma)\n",
    "pip_gaussian = make_pipeline(MinMaxScaler((-1,1)),StandardScaler(),gs_gaussian)\n",
    "\n",
    "pip_gaussian.fit(Xa,ya)\n",
    "out=pip_gaussian.predict(Xtest_1d)\n",
    "score = accuracy_score(y_test, out)\n",
    "print(score) # C=4.4, log10(gamma) = -3.5, score=0.338\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Linear kernel\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "n = 10000\n",
    "Xa,ya=gethomogeneus_datast(Xtrain_1d,y_train,10,n)    \n",
    "\n",
    "parameters = {'C':np.arange(0.00001,0.1,0.025)}\n",
    "gs_gaussian = GridSearchCV(SVC(kernel='linear'),param_grid=parameters)\n",
    "\n",
    "pip_gaussian = make_pipeline(StandardScaler(),gs_gaussian)\n",
    "pip_gaussian.fit(Xa,ya)\n",
    "\n",
    "C_best = gs_gaussian.best_params_['C']\n",
    "\n",
    "out=pip_gaussian.predict(Xtest_1d)\n",
    "score = accuracy_score(y_test, out)\n",
    "print(score) # C=0.1, score(not 1-score )=0.4869\n",
    "print('best C:',C_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### Gaussian kernel grid search\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "\n",
    "gammavec = 10**np.arange(-4,-3.5,0.1) #0.3-1.5(0.25) got 1.995 #(-1,0.5,0.1) got 0.5\n",
    "gammavec.shape = (gammavec.shape[0])\n",
    "Cvec = np.arange(3.8,4.2,0.1) #3-5(0.25))got 4.25  #4-5, 4.0 (0.5)\n",
    "Cvec.shape=(Cvec.shape[0])\n",
    "parameters = {\"C\":Cvec,\n",
    "              \"gamma\":gammavec}\n",
    "\n",
    "gs_gaussian = GridSearchCV(SVC(kernel='rbf',tol=0.1),parameters)\n",
    "pip_gaussian = make_pipeline(StandardScaler(),gs_gaussian)\n",
    "n = 10000\n",
    "Xa,ya=gethomogeneus_datast(Xtrain_1d,y_train,10,n)\n",
    "\n",
    "start = time.time()\n",
    "pip_gaussian.fit(Xa,ya.ravel())\n",
    "\n",
    "bestC = gs_gaussian.best_params_['C']\n",
    "bestgamma = gs_gaussian.best_params_['gamma']\n",
    "print(np.log10(bestgamma))\n",
    "print(bestC)\n",
    "out=pip_gaussian.predict(Xtest_1d)\n",
    "\n",
    "score = accuracy_score(y_test, out)\n",
    "print(score) # gamma = -3.5, C=4.1, score=0.4179, tol = 0.1 , time: 45.95646786689758,n=300\n",
    "print('time:',time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.5\n"
     ]
    }
   ],
   "source": [
    "n=10000, tol = 0.1\n",
    "\n",
    "n=1000, tol = 0.1\n",
    "-3.6\n",
    "3.8\n",
    "0.5169\n",
    "time: 387.4123179912567\n",
    "\n",
    "tol = 0.01 \n",
    "-3.6\n",
    "3.8\n",
    "0.5169\n",
    "time: 461.48333406448364\n",
    "\n",
    "\n",
    "________________________\n",
    "n = 300, tol = 0.001\n",
    "-3.5\n",
    "4.1\n",
    "0.4185\n",
    "time: 46.558130979537964\n",
    "    \n",
    "-3.6\n",
    "4.0\n",
    "0.4204\n",
    "time: 36.48983287811279\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler, Normalizer\n",
    "\n",
    "gammavec = np.array(10**np.arange(0.46,0.52,0.01)) #np.array(10**np.arange(-0.1,1,0.3))  best 0.5 #np.array(10**np.arange(-3,-0.5,0.1)) got 0.0063095734448\n",
    "gammavec.shape = (6)\n",
    "Cvec = np.arange(3.8,3.95,0.05)\n",
    "#Cvec.append(1) #np.arange(3.15,3.55,0.10) #np.arange(0.5,4,0.25) got 3.25\n",
    "Cvec.shape=(4)\n",
    "parameters = {\"C\":Cvec,\n",
    "              \"gamma\":gammavec}\n",
    "\n",
    "gs_gaussian = GridSearchCV(SVC(kernel='rbf'),parameters)\n",
    "pip_gaussian = make_pipeline(StandardScaler(),gs_gaussian)\n",
    "pip_gaussian.fit(Xa,ya)\n",
    "\n",
    "bestC = gs_gaussian.best_params_['C']\n",
    "bestgamma = gs_gaussian.best_params_['gamma']\n",
    "print(bestC)\n",
    "print(bestgamma)\n",
    "gs_gaussian = SVC(kernel='rbf',C=bestC,gamma=bestgamma)\n",
    "pip_gaussian = make_pipeline(MinMaxScaler((-1,1)),Normalizer(),gs_gaussian)\n",
    "\n",
    "pip_gaussian.fit(Xa,ya)\n",
    "out=pip_gaussian.predict(Xtest_1d)\n",
    "score = 1.0-accuracy_score(ytest, out)\n",
    "print(score) # C=3, gamma = 3.16227766, score=0.0139\n",
    "#C=3.9, gamma = 2.88403150313 score=0.0137"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage.color.colorconv import rgb2yuv,yuv2rgb\n",
    "\n",
    "Xta = X_train.transpose((3,2,0,1))/255\n",
    "Iyuv=rgb2yuv(Xta)\n",
    "Iyuv = Iyuv.transpose((2,3,0,1)).copy()\n",
    "Iyuv.shape = (num_samples*3,32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im = Iyuv[0:3,:,:].transpose((1,2,0))                      \n",
    "imvuelta = yuv2rgb(im)\n",
    "imvuelta.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt \n",
    "%matplotlib inline\n",
    "indx = 0\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(imvuelta)\n",
    "plt.subplot(1,2,2)\n",
    "x = X_train[indx,:,:,:]\n",
    "x.shape\n",
    "plt.imshow(x.transpose((2,1,0))/255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt \n",
    "%matplotlib inline\n",
    "indx = 0\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(Ivuelta[:,:,indx,:])\n",
    "plt.subplot(1,2,2)\n",
    "x = X_train[indx,:,:,:]\n",
    "x.shape\n",
    "plt.imshow(x.transpose((2,1,0))/255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 60000\n",
    "from load_mnist_db import load_scattering_mnist\n",
    "\n",
    "import time as time\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "num_images = n\n",
    "px=32\n",
    "\n",
    "Xtrain,ytrain,Xtest,ytest = load_scattering_mnist(num_images = num_images, px=px,J=3,L=6,m=2)\n",
    "Xtrain_1d = Xtrain.reshape((len(Xtrain),-1))\n",
    "num_samples,num_features = Xtrain_1d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtrain_1d = Xtrain.reshape((len(Xtrain),-1))\n",
    "Xtest_1d = Xtest.reshape((len(Xtest),-1))\n",
    "Xtest_1d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import os, sys\n",
    "import scipy.misc\n",
    "import scipy.io\n",
    "print('saving data in ./mnist_scat_complet.mat')\n",
    "\n",
    "scipy.io.savemat('./mnist_scat_complet.mat', \n",
    "                 mdict={'ytest': ytest, 'xtest': Xtest, \n",
    "                        'ytrain': ytrain, 'xtrain': Xtrain })\n",
    "print('saving done!')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "f = h5py.File('mnist_scat_complet.mat')\n",
    "Xtrain = np.array(f['xtrain']).transpose(3,2,1,0)\n",
    "Xtest = np.array(f['xtest']).transpose(3,2,1,0)\n",
    "ytrain = f['ytrain']\n",
    "ytest = f['ytest']\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gethomogeneus_datast(X,y,d,n):\n",
    "    num_per_class = np.int(n/d)\n",
    "    ytrain=np.reshape(y,(y.shape[0],))\n",
    "\n",
    "    X_out = []#np.zeros(n,X.shape[1],X.shape[2],X.shape[3])\n",
    "    y_out = []\n",
    "    for i_d in np.arange(d):\n",
    "        indx = np.where(ytrain.ravel()==i_d)\n",
    "\n",
    "        X_out.append(X[indx[0][0:num_per_class],:])\n",
    "        y_out.append(ytrain[indx[0][0:num_per_class],])\n",
    "\n",
    "    \n",
    "    X_out = np.concatenate(X_out,axis=0)\n",
    "    y_out = np.concatenate(y_out,axis=0)\n",
    "    #print(X_out.shape)\n",
    "    #print(y_out)\n",
    "    return X_out,y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gammavec = 10**np.arange(-3,-1,0.1)\n",
    "gammavec.shape = (gammavec.shape[0])\n",
    "gammavec.shape\n",
    "Cvec = np.arange(1,3.5,0.5)\n",
    "Cvec.shape=(Cvec.shape[0])\n",
    "Cvec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### Gaussian kernel grid search\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
    "\n",
    "\n",
    "#gammavec = 10**np.arange(-2.25,-2.15,0.01)# got 0.00616595 #np.array(10**np.arange(-3,-0.5,0.1)) got 0.0063095734448\n",
    "gammavec = 10**np.arange(0.,0.15,0.05) #0.3-1.5(0.25) got 1.995 #(-1,0.5,0.1) got 0.5\n",
    "gammavec.shape = (gammavec.shape[0])\n",
    "#Cvec = np.arange(3.15,3.55,0.10) #got 3.25 #np.arange(0.5,4,0.25) got 3.25\n",
    "Cvec = np.arange(4.1,4.4,0.1) #3-5(0.25))got 4.25  #4-5, 4.0 (0.5)\n",
    "Cvec.shape=(Cvec.shape[0])\n",
    "parameters = {\"C\":Cvec,\n",
    "              \"gamma\":gammavec}\n",
    "\n",
    "gs_gaussian = GridSearchCV(SVC(kernel='rbf'),parameters)\n",
    "pip_gaussian = make_pipeline(MinMaxScaler((-1,1)),Normalizer(),gs_gaussian)\n",
    "n = 10000\n",
    "Xa,ya=gethomogeneus_datast(Xtrain_1d,ytrain,10,n)\n",
    "\n",
    "np.histogram(ya)\n",
    "\n",
    "pip_gaussian.fit(Xa,ya.ravel())\n",
    "\n",
    "bestC = gs_gaussian.best_params_['C']\n",
    "bestgamma = gs_gaussian.best_params_['gamma']\n",
    "print(bestgamma)\n",
    "print(bestC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.log10(1.1220184543)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bestC = 4\n",
    "bestgamma =10**0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(np.log10(bestgamma))\n",
    "gammavec\n",
    "print(10**np.arange(-2.25,-2.15,0.01))\n",
    "#print(gammavec)\n",
    "print(bestgamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(bestC)\n",
    "Cvec\n",
    "np.arange(3.15,3.55,0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "########### Gaussian kernel methods\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler, Normalizer\n",
    "\n",
    "num_items,num_features = Xtrain_1d.shape\n",
    "\n",
    "ns = [300, 1000, 2000, 5000, 10000,20000, 40000, 60000]\n",
    "score_gaussian = np.zeros((len(ns),1))\n",
    "for i,n in enumerate(ns):\n",
    "    #  gs_gaussian = GridSearchCV(SVC(kernel='rbf'),param_grid=parameters)\n",
    "    gs_gaussian = SVC(kernel='rbf',C=bestC,gamma=bestgamma)\n",
    "    pip_gaussian = make_pipeline(MinMaxScaler((-1,1)),Normalizer(),gs_gaussian)\n",
    "\n",
    "#    gs_gaussian = SVC(kernel='rbf',gamma=0.0018)\n",
    "#    pip_gaussian = make_pipeline(StandardScaler(),Normalizer(),gs_gaussian)\n",
    "\n",
    "    Xa,ya=gethomogeneus_datast(Xtrain_1d,ytrain,10,n) \n",
    "    pip_gaussian.fit(Xa,ya)\n",
    "    out=pip_gaussian.predict(Xtest_1d)\n",
    "    score_gaussian[i] = 1.0-accuracy_score(ytest, out)\n",
    "    print(score_gaussian[i])\n",
    "    \n",
    "score_gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(bestC)\n",
    "print(bestgamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.arange(-3,-0.5,0.1).shape\n",
    "n = 10000\n",
    "Xa,ya=gethomogeneus_datast(Xtrain_1d,ytrain,10,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler, Normalizer\n",
    "\n",
    "gammavec = np.array(10**np.arange(0.46,0.52,0.01)) #np.array(10**np.arange(-0.1,1,0.3))  best 0.5 #np.array(10**np.arange(-3,-0.5,0.1)) got 0.0063095734448\n",
    "gammavec.shape = (6)\n",
    "Cvec = np.arange(3.8,3.95,0.05)\n",
    "#Cvec.append(1) #np.arange(3.15,3.55,0.10) #np.arange(0.5,4,0.25) got 3.25\n",
    "Cvec.shape=(4)\n",
    "parameters = {\"C\":Cvec,\n",
    "              \"gamma\":gammavec}\n",
    "\n",
    "gs_gaussian = GridSearchCV(SVC(kernel='rbf'),parameters)\n",
    "pip_gaussian = make_pipeline(MinMaxScaler((-1,1)),Normalizer(),gs_gaussian)\n",
    "pip_gaussian.fit(Xa,ya)\n",
    "\n",
    "bestC = gs_gaussian.best_params_['C']\n",
    "bestgamma = gs_gaussian.best_params_['gamma']\n",
    "print(bestC)\n",
    "print(bestgamma)\n",
    "gs_gaussian = SVC(kernel='rbf',C=bestC,gamma=bestgamma)\n",
    "pip_gaussian = make_pipeline(MinMaxScaler((-1,1)),Normalizer(),gs_gaussian)\n",
    "\n",
    "pip_gaussian.fit(Xa,ya)\n",
    "out=pip_gaussian.predict(Xtest_1d)\n",
    "score = 1.0-accuracy_score(ytest, out)\n",
    "print(score) # C=3, gamma = 3.16227766, score=0.0139\n",
    "#C=3.9, gamma = 2.88403150313 score=0.0137"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler,Normalizer\n",
    "\n",
    "n = 10000\n",
    "Xa,ya=gethomogeneus_datast(Xtrain_1d,ytrain,10,n)    \n",
    "\n",
    "parameters = {'C':np.arange(0.75,5,0.25)}\n",
    "gs_gaussian = GridSearchCV(SVC(kernel='linear'),param_grid=parameters)\n",
    "\n",
    "pip_gaussian = make_pipeline(MinMaxScaler((-1,1)),Normalizer(),gs_gaussian)\n",
    "pip_gaussian.fit(Xa,ya)\n",
    "\n",
    "C_best = gs_gaussian.best_params_['C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "C_best = gs_gaussian.best_params_['C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### linear\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler,Normalizer\n",
    "\n",
    "num_items,num_features = Xtrain_1d.shape\n",
    "\n",
    "ns = [300, 1000, 2000, 5000, 10000]\n",
    "score_gaussian = np.zeros((5,1))\n",
    "for i,n in enumerate(ns):\n",
    "    #  gs_gaussian = GridSearchCV(SVC(kernel='rbf'),param_grid=parameters)\n",
    "    gs_gaussian = SVC(kernel='linear',C=C_best)\n",
    "    pip_gaussian = make_pipeline(MinMaxScaler((-1,1)),Normalizer(),gs_gaussian)\n",
    "\n",
    "#    gs_gaussian = SVC(kernel='rbf',gamma=0.0018)\n",
    "#    pip_gaussian = make_pipeline(StandardScaler(),Normalizer(),gs_gaussian)\n",
    "\n",
    "    Xa,ya=gethomogeneus_datast(Xtrain_1d,ytrain,10,n)    \n",
    "    pip_gaussian.fit(Xa,ya)\n",
    "    out=pip_gaussian.predict(Xtest_1d)\n",
    "    score_gaussian[i] = 1.0-accuracy_score(ytest, out)\n",
    "    print(score_gaussian[i])\n",
    "    \n",
    "score_gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtest_1d = Xtest.reshape((len(Xtest),-1))\n",
    "Xe = normalize(Xtest_1d)\n",
    "Xe = scale(Xe)\n",
    "\n",
    "predictedY = gs_linear.predict(Xe)\n",
    "score = accuracy_score(ytest, predictedY)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {\"C\":[1,1.1,1.11,1.05] ,\n",
    "              \"gamma\":[0.1/num_features,1/num_features,10./num_features]}\n",
    "gs_gaussian = GridSearchCV(SVC(kernel='rbf'),param_grid=parameters)\n",
    "\n",
    "X = normalize(Xtrain_1d[0:n,:])\n",
    "X = scale(X)\n",
    "\n",
    "gs_gaussian.fit(X,ytrain[0:n])\n",
    "gs_gaussian.best_params_\n",
    "\n",
    "Xtest_1d = Xtest.reshape((len(Xtest),-1))\n",
    "Xe = normalize(Xtest_1d)\n",
    "Xe = scale(Xe)\n",
    "\n",
    "predictedY = gs_gaussian.predict(Xe)\n",
    "score = accuracy_score(ytest, predictedY)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('mine:',np.sum(ytest==predictedY)/len(Xtest))\n",
    "print('two:',accuracy_score(ytest, predictedY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sampling the whole dataset \n",
    "n = 300\n",
    "train_size=n/60000\n",
    "test_size=0.5*n/60000\n",
    "\n",
    "pipeline = make_pipeline(Normalizer(),StandardScaler(),gs)\n",
    "\n",
    "# pipeline = make_pipeline(Normalizer(),StandardScaler(),SVC(C=1.0, kernel='rbf', verbose=False))\n",
    "cv = ShuffleSplit(n,n_iter=3,test_size=test_size, train_size=train_size)\n",
    "\n",
    "scores = cross_val_score(pipeline,Xtrain_1d[0:n,:],ytrain[0:n],cv=10)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % ((1.0-scores.mean())*100, scores.std() * 2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gs.best_params_\n",
    "pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.cross_validation import cross_val_score, KFold, ShuffleSplit,cross_val_predict\n",
    "from sklearn import metrics\n",
    "\n",
    "def from_features_to_classif_scores(features,labels,ftest,ltest):\n",
    "    #stack them for learning\n",
    "    features = features.reshape((len(features),-1))\n",
    "    ftest = ftest.reshape((len(ftest),-1))\n",
    "    # apply pipeline\n",
    "    n = len(features)\n",
    "    \n",
    "    pipeline = make_pipeline(Normalizer(),StandardScaler(),SVC(C=1.0, kernel='rbf', verbose=False))\n",
    "    cv = ShuffleSplit(n,n_iter=3,test_size=0.1, train_size=0.9)\n",
    "    \n",
    "    scores = cross_val_score(pipeline,features,labels,cv=10)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % ((1.0-scores.mean())*100, scores.std() * 2*100))\n",
    "    print('min score:',(1.0-scores.max())*100)\n",
    "    return pipeline,scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from load_mnist_db import load_scattering_mnist\n",
    "import time as time\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "\n",
    "num_images = 60000\n",
    "px=32\n",
    "\n",
    "Xtrain,ytrain,Xtest,ytest = load_scattering_mnist(num_images = num_images, px=px,J=3,L=8)\n",
    "\n",
    "num_points = [330, 1100, 2200, 5500, 11000, 22000, 60000]\n",
    "for n in num_points:\n",
    "    print('n=',n)\n",
    "    pipeline, test_err = from_features_to_classif_scores(Xtrain[0:n,:,:,:],ytrain[0:n],Xtest[0:n,:,:,:],ytest[0:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X_train = Xtrain\n",
    "y_train = ytrain\n",
    "X_train = features.reshape((len(X_train),-1))\n",
    "X_test = Xtest.reshape((len(Xtest),-1))\n",
    "\n",
    "# apply pipeline\n",
    "n = len(X_train)\n",
    "\n",
    "pipeline = make_pipeline(Normalizer(),StandardScaler(),SVC(C=1.0, kernel='rbf', verbose=True))\n",
    "#cv = ShuffleSplit(n,n_iter=3,test_size=1, train_size=1)\n",
    "\n",
    "normalizer = Normalizer()\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_normalized = normalizer.transform(X_train)\n",
    "X_train_transformed = scaler.transform(X_train_normalized)\n",
    "\n",
    "clf = SVC(kernel='rbf', C=1, verbose=True).fit(X_train_transformed, y_train)\n",
    "\n",
    "X_test_normalized = normalizer.transform(X_test)\n",
    "X_test_transformed = scaler.transform(X_test_normalized)\n",
    "\n",
    "clf.score(Xtest, ytest)   \n",
    "\n",
    "\n",
    "print('score:',scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

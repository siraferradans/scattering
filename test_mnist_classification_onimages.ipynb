{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.cross_validation import cross_val_score, KFold, ShuffleSplit,cross_val_predict\n",
    "from sklearn import metrics\n",
    "\n",
    "def from_features_to_classif_scores(features,labels,ftest,ltest):\n",
    "    #stack them for learning\n",
    "    features = features.reshape((len(features),-1))\n",
    "    ftest = ftest.reshape((len(ftest),-1))\n",
    "    # apply pipeline\n",
    "    n = len(features)\n",
    "    \n",
    "    gs = GridSearchCV(SVC(kernel='rbf'), param_grad={'gamma',[0.01,0.05,0.1,0.11,0.15],'C',[0.8,0.9,1,1.1,1.2]})\n",
    "    pipeline = make_pipeline(Normalizer(),StandardScaler(),gs)\n",
    "    \n",
    "    # pipeline = make_pipeline(Normalizer(),StandardScaler(),SVC(C=1.0, kernel='rbf', verbose=False))\n",
    "    cv = ShuffleSplit(n,n_iter=3,test_size=1, train_size=1)\n",
    "    \n",
    "    scores = cross_val_score(pipeline,features,labels,cv=10)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % ((1.0-scores.mean())*100, scores.std() * 2*100))\n",
    "\n",
    "    return pipeline,scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_images_ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 32, 32)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "n = 60000\n",
    "from load_mnist_db import load_images_mnist\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import time as time\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "num_images = n\n",
    "px=32\n",
    "\n",
    "Xtrain,ytrain,Xtest,ytest = load_images_mnist(px=px)\n",
    "\n",
    "Xtrain_1d = Xtrain.reshape((len(Xtrain),-1))\n",
    "Xtest_1d = Xtest.reshape((len(Xtest),-1))\n",
    "\n",
    "num_samples,num_features = Xtrain_1d.shape\n",
    "\n",
    "\n",
    "#num2vec=OneHotEncoder()\n",
    "\n",
    "#ytrain_1d.shape=(num_samples,1)\n",
    "#num2vec.fit(ytrain_1d)\n",
    "\n",
    "#ytrain=num2vec.transform(ytrain_1d)\n",
    "\n",
    "#ytest_1d.shape=(ytest_1d.shape[0],1)\n",
    "#ytest=num2vec.transform(ytest_1d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "bad input shape (300, 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-854cd9419807>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mpip_linear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mpip_linear\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain_1d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpip_linear\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest_1d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ferradans/anaconda3/lib/python3.5/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \"\"\"\n\u001b[1;32m    164\u001b[0m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pre_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ferradans/anaconda3/lib/python3.5/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         sample_weight = np.asarray([]\n",
      "\u001b[0;32m/Users/ferradans/anaconda3/lib/python3.5/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_validate_targets\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m         \u001b[0my_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ferradans/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bad input shape {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: bad input shape (300, 10)"
     ]
    }
   ],
   "source": [
    "################## Linear SVM\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "ns = [300, 1000, 2000, 5000, 10000]\n",
    "score = np.zeros((5,1))\n",
    "for i,n in enumerate(ns):\n",
    "    pip_linear = make_pipeline(SVC(kernel='linear',C=1))\n",
    "\n",
    "    pip_linear.fit(Xtrain_1d[0:n,:],ytrain[0:n,:])\n",
    "    out=pip_linear.predict(Xtest_1d)\n",
    "    score[i] = 1.0-accuracy_score(ytest, out)\n",
    "\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4], dtype=uint8)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain[0:3].transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 1 9 2 1 3 1 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "vv=OneHotEncoder()\n",
    "vector =ytrain[0:10]\n",
    "print(vector)\n",
    "\n",
    "vector.shape=(10,1)\n",
    "aa=vv.fit(vector)\n",
    "output=vv.transform(vector[0:4,:])\n",
    "output.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1024)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cvec = np.arange(0.01,2,0.2)\n",
    "Cvec.shape\n",
    "Xtrain_1d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.58489319246\n",
      "1.41\n"
     ]
    }
   ],
   "source": [
    "################## Cross-validation for Gaussian SVM\n",
    "gammavec = np.array(10**np.arange(-3,1,0.4))\n",
    "gammavec.shape = (10)\n",
    "Cvec = np.arange(0.01,2,0.2)\n",
    "Cvec.shape=(10)\n",
    "parameters = {\"C\":Cvec,\n",
    "              \"gamma\":gammavec}\n",
    "\n",
    "gs_gaussian = GridSearchCV(SVC(kernel='rbf'),parameters)\n",
    "pip_gaussian = make_pipeline(Normalizer(),gs_gaussian)\n",
    "n = 4000\n",
    "pip_gaussian.fit(Xtrain_1d[0:n,:],ytrain[0:n].ravel())\n",
    "\n",
    "bestC = gs_gaussian.best_params_['C']\n",
    "bestgamma = gs_gaussian.best_params_['gamma']\n",
    "print(bestgamma)\n",
    "print(bestC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.58489319246\n",
      "1.41\n"
     ]
    }
   ],
   "source": [
    "gs_gaussian.best_score_\n",
    "bestC = gs_gaussian.best_params_['C']\n",
    "bestgamma = gs_gaussian.best_params_['gamma']\n",
    "print(bestgamma)\n",
    "print(bestC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.09475,  0.111  ,  0.09925,  0.098  ,  0.1075 ,  0.0875 ,\n",
       "        0.10125,  0.10825,  0.09325,  0.09925])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.histogram(ytrain[0:4000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sort_scats_per_class(X,y)\n",
    "\n",
    "    num_classes = y.max()-y.min()\n",
    "    \n",
    "\n",
    "\n",
    "Xtrain_well_distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.1533]\n",
      "[ 0.0773]\n",
      "[ 0.0594]\n",
      "[ 0.0404]\n",
      "[ 0.0327]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.1533],\n",
       "       [ 0.0773],\n",
       "       [ 0.0594],\n",
       "       [ 0.0404],\n",
       "       [ 0.0327]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "\n",
    "num_items,num_features = Xtrain_1d.shape\n",
    "#parameters = {\"C\":[1],\n",
    "#              \"gamma\":[1./num_features]}\n",
    "\n",
    "parameters = {\"C\":[np.arange(0.01,2,10)],\n",
    "              \"gamma\":[10**np.arange(-3,1,10)]}\n",
    "\n",
    "\n",
    "ns = [300, 1000, 2000, 5000, 10000]\n",
    "score_gaussian = np.zeros((5,1))\n",
    "for i,n in enumerate(ns):\n",
    "    #  gs_gaussian = GridSearchCV(SVC(kernel='rbf'),param_grid=parameters)\n",
    "    gs_gaussian = SVC(kernel='rbf',C=bestC,gamma=bestgamma)\n",
    "    pip_gaussian = make_pipeline(Normalizer(),gs_gaussian)\n",
    "\n",
    "    pip_gaussian.fit(Xtrain_1d[0:n,:],ytrain[0:n])\n",
    "    out=pip_gaussian.predict(Xtest_1d)\n",
    "    score_gaussian[i] = 1.0-accuracy_score(ytest, out)\n",
    "    print(score_gaussian[i])\n",
    "    \n",
    "score_gaussian\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1024)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_1d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46.0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J=3\n",
    "L=6\n",
    "N=32\n",
    "uu=4#N/2**(J)\n",
    "\n",
    "4096/(J*L+J*(J-1)*L*L/2)\n",
    "#(1+J*L+J*(J-1)*L*L/2)*uu*uu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0004921259842519685\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.9212598425196856e-05, 0.0004921259842519685, 0.004921259842519685]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(gamma)\n",
    "parameters['gamma']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84819999999999995"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pip_gaussian2 = make_pipeline(StandardScaler(),SVC(kernel='rbf',C=C,gamma=gamma))\n",
    "\n",
    "pip_gaussian2.fit(Xtrain_1d[0:n,:],ytrain[0:n].ravel())\n",
    "out=pip_gaussian2.predict(Xtest_1d)\n",
    "score = accuracy_score(ytest, out)\n",
    "score\n",
    "\n",
    "#for n in np.arange(300\n",
    "#X = normalize(Xtrain_1d[2*n:3*n,:])\n",
    "#X = scale(X)\n",
    "\n",
    "#gs_linear.fit(X,ytrain[2*n:3*n])\n",
    "#gs_linear.best_params_\n",
    "\n",
    "#Xtest_1d = Xtest.reshape((len(Xtest),-1))\n",
    "#Xe = normalize(Xtest_1d)\n",
    "#Xe = scale(Xe)\n",
    "\n",
    "#predictedY = gs_linear.predict(Xtest_1d)\n",
    "#score = accuracy_score(ytest, predictedY)\n",
    "#score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gs_linear.best_params_['C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtest_1d = Xtest.reshape((len(Xtest),-1))\n",
    "Xe = normalize(Xtest_1d)\n",
    "Xe = scale(Xe)\n",
    "\n",
    "predictedY = gs_linear.predict(Xe)\n",
    "score = accuracy_score(ytest, predictedY)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "parameters = {\"C\":[1,1.1,1.11,1.05] ,\n",
    "              \"gamma\":[0.1/num_features,1/num_features,10./num_features]}\n",
    "gs_gaussian = GridSearchCV(SVC(kernel='rbf'),param_grid=parameters)\n",
    "\n",
    "X = normalize(Xtrain_1d[0:n,:])\n",
    "X = scale(X)\n",
    "\n",
    "gs_gaussian.fit(X,ytrain[0:n])\n",
    "gs_gaussian.best_params_\n",
    "\n",
    "Xtest_1d = Xtest.reshape((len(Xtest),-1))\n",
    "Xe = normalize(Xtest_1d)\n",
    "Xe = scale(Xe)\n",
    "\n",
    "predictedY = gs_gaussian.predict(Xe)\n",
    "score = accuracy_score(ytest, predictedY)\n",
    "score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('mine:',np.sum(ytest==predictedY)/len(Xtest))\n",
    "print('two:',accuracy_score(ytest, predictedY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#sampling the whole dataset \n",
    "n = 300\n",
    "train_size=n/60000\n",
    "test_size=0.5*n/60000\n",
    "\n",
    "pipeline = make_pipeline(Normalizer(),StandardScaler(),gs)\n",
    "\n",
    "# pipeline = make_pipeline(Normalizer(),StandardScaler(),SVC(C=1.0, kernel='rbf', verbose=False))\n",
    "cv = ShuffleSplit(n,n_iter=3,test_size=test_size, train_size=train_size)\n",
    "\n",
    "scores = cross_val_score(pipeline,Xtrain_1d[0:n,:],ytrain[0:n],cv=10)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % ((1.0-scores.mean())*100, scores.std() * 2*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gs.best_params_\n",
    "pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.cross_validation import cross_val_score, KFold, ShuffleSplit,cross_val_predict\n",
    "from sklearn import metrics\n",
    "\n",
    "def from_features_to_classif_scores(features,labels,ftest,ltest):\n",
    "    #stack them for learning\n",
    "    features = features.reshape((len(features),-1))\n",
    "    ftest = ftest.reshape((len(ftest),-1))\n",
    "    # apply pipeline\n",
    "    n = len(features)\n",
    "    \n",
    "    pipeline = make_pipeline(Normalizer(),StandardScaler(),SVC(C=1.0, kernel='rbf', verbose=False))\n",
    "    cv = ShuffleSplit(n,n_iter=3,test_size=0.1, train_size=0.9)\n",
    "    \n",
    "    scores = cross_val_score(pipeline,features,labels,cv=10)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % ((1.0-scores.mean())*100, scores.std() * 2*100))\n",
    "    print('min score:',(1.0-scores.max())*100)\n",
    "    return pipeline,scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from load_mnist_db import load_scattering_mnist\n",
    "import time as time\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "\n",
    "num_images = 60000\n",
    "px=32\n",
    "\n",
    "Xtrain,ytrain,Xtest,ytest = load_scattering_mnist(num_images = num_images, px=px,J=3,L=8)\n",
    "\n",
    "num_points = [330, 1100, 2200, 5500, 11000, 22000, 60000]\n",
    "for n in num_points:\n",
    "    print('n=',n)\n",
    "    pipeline, test_err = from_features_to_classif_scores(Xtrain[0:n,:,:,:],ytrain[0:n],Xtest[0:n,:,:,:],ytest[0:n])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X_train = Xtrain\n",
    "y_train = ytrain\n",
    "X_train = features.reshape((len(X_train),-1))\n",
    "X_test = Xtest.reshape((len(Xtest),-1))\n",
    "\n",
    "# apply pipeline\n",
    "n = len(X_train)\n",
    "\n",
    "pipeline = make_pipeline(Normalizer(),StandardScaler(),SVC(C=1.0, kernel='rbf', verbose=True))\n",
    "#cv = ShuffleSplit(n,n_iter=3,test_size=1, train_size=1)\n",
    "\n",
    "normalizer = Normalizer()\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_normalized = normalizer.transform(X_train)\n",
    "X_train_transformed = scaler.transform(X_train_normalized)\n",
    "\n",
    "clf = SVC(kernel='rbf', C=1, verbose=True).fit(X_train_transformed, y_train)\n",
    "\n",
    "X_test_normalized = normalizer.transform(X_test)\n",
    "X_test_transformed = scaler.transform(X_test_normalized)\n",
    "\n",
    "clf.score(Xtest, ytest)   \n",
    "\n",
    "\n",
    "print('score:',scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
